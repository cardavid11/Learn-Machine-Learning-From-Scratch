{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import xgboost as xgboost\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "dataset = pd.read_csv('./dataset/bank-full.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset.describe()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate the x and y variables\n",
    "y = dataset.iloc[:, -1].values\n",
    "X = dataset._get_numeric_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into traininig and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=1502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12175163109587527"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform y factor variables\n",
    "y_train = np.where(y_train == 'yes', 1, 0)\n",
    "y_test = np.where(y_test == 'yes', 1, 0)\n",
    "np.mean(y_train) #11.5% is our baseline, we need to beat this\n",
    "np.mean(y_test) #12.17%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create xgbosst matrices\n",
    "Train = xgboost.DMatrix(X_train, label = y_train)\n",
    "Test = xgboost.DMatrix(X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters\n",
    "parameters1 = {\n",
    "    'learning_rate': 0.3,\n",
    "    'max_depth': 2,\n",
    "    'colsample_bytree': 1,\n",
    "    'subsample': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'random_state': 1502,\n",
    "    'eval_metric': 'auc', \n",
    "    'objective': 'binary:logistic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-auc:0.75049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tTest-auc:0.87633\n",
      "[100]\tTest-auc:0.88087\n",
      "[150]\tTest-auc:0.88275\n",
      "[199]\tTest-auc:0.88375\n"
     ]
    }
   ],
   "source": [
    "#run XGBoost\n",
    "model = xgboost.train(params = parameters1, \n",
    "                      dtrain = Train, \n",
    "                      num_boost_round = 200,\n",
    "                      evals = [(Test, 'Test')],\n",
    "                      verbose_eval = 50\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions \n",
    "predictions1 =  model.predict(Test)\n",
    "predictions1 = np.where(predictions1 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7690  252]\n",
      " [ 736  365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      7942\n",
      "           1       0.59      0.33      0.42      1101\n",
      "\n",
      "    accuracy                           0.89      9043\n",
      "   macro avg       0.75      0.65      0.68      9043\n",
      "weighted avg       0.87      0.89      0.88      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "# see lesson 27 for more details\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "confusion_matrix1 = confusion_matrix(y_test, predictions1)\n",
    "print(confusion_matrix1)\n",
    "report1 = classification_report(y_test, predictions1)\n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Transforming categorical variables into dummy variables\n",
    "# Isolate the categorical variables\n",
    "dataset_categorical = dataset.select_dtypes(exclude = \"number\")\n",
    "\n",
    "# Transform categorical variables into dummy variables\n",
    "dataset_categorical = pd.get_dummies(dataset_categorical, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining numerical and categorical datasets\n",
    "final_dataset = pd.concat([X, dataset_categorical], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting names of columns\n",
    "feature_columns = list(final_dataset.columns.values)\n",
    "feature_columns = feature_columns[:-1]\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate the x and y variables Part 2\n",
    "y = final_dataset.iloc[:, -1].values\n",
    "X = final_dataset.iloc[:, :-1].values\n",
    "\n",
    "#Split dataset into traininig and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=1502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create xgbosst matrices Part 2\n",
    "Train = xgboost.DMatrix(X_train, label = y_train, feature_names = feature_columns)\n",
    "Test = xgboost.DMatrix(X_test, label = y_test, feature_names = feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-auc:0.74351\n",
      "[50]\tTest-auc:0.91916\n",
      "[100]\tTest-auc:0.92513\n",
      "[150]\tTest-auc:0.92809\n",
      "[199]\tTest-auc:0.92905\n"
     ]
    }
   ],
   "source": [
    "#Set parameters Part 2\n",
    "parameters2 = {\n",
    "    'learning_rate': 0.3,\n",
    "    'max_depth': 2,\n",
    "    'colsample_bytree': 1,\n",
    "    'subsample': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'random_state': 1502,\n",
    "    'eval_metric': 'auc', \n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "\n",
    "#run XGBoost Part 2\n",
    "model2 = xgboost.train(params = parameters2, \n",
    "                      dtrain = Train, \n",
    "                      num_boost_round = 200,\n",
    "                      evals = [(Test, 'Test')],\n",
    "                      verbose_eval = 50\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions Part 2\n",
    "predictions2 =  model2.predict(Test)\n",
    "predictions2 = np.where(predictions2 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7676  266]\n",
      " [ 628  473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.97      0.94      7942\n",
      "        True       0.64      0.43      0.51      1101\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.78      0.70      0.73      9043\n",
      "weighted avg       0.89      0.90      0.89      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "# see lesson 27 for more details\n",
    "confusion_matrix2 = confusion_matrix(y_test, predictions2)\n",
    "print(confusion_matrix2)\n",
    "report2 = classification_report(y_test, predictions2)\n",
    "print(report2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "\n",
    "#Checking how many minicores we have\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()\n",
    "\n",
    "#Setting the cross validation parameters\n",
    "from sklearn.model_selection import KFold\n",
    "tune_control = KFold(n_splits = 5, \n",
    "                     shuffle = True, \n",
    "                     random_state = 1502).split(X = X_train, \n",
    "                                                y = y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter tuning\n",
    "#Set parameters Part 3\n",
    "tune_grid = {\n",
    "    'learning_rate': [0.05, 0.3],\n",
    "    'max_depth': range(2,9,2),\n",
    "    'colsample_bytree': [0.05, 1],\n",
    "    'subsample': [1],\n",
    "    'min_child_weight': [1],\n",
    "    'gamma': [0],\n",
    "    'random_state': [1502],\n",
    "    \"n_estimators\": range(200, 2000, 200),\n",
    "    \"booster\": [\"gbtree\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State that we are doing a classification problem\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(objective = \"binary:logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation Assembly\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = tune_grid,\n",
    "                           scoring = \"roc_auc\",\n",
    "                           cv = tune_control,\n",
    "                           n_jobs = 6,\n",
    "                           verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting evaluation parameters\n",
    "evaluation_parameters = {\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"eval_set\": [(X_test, y_test)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Documents\\GitHub\\Learn-Machine-Learning-From-Scratch\\Additional Applications\\XGBoost\\xgboost.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Hyperparameter tuning and cross validation\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tune_model \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mfit(X \u001b[39m=\u001b[39m X_train, y \u001b[39m=\u001b[39m y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mevaluation_parameters)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\carlo\\miniconda3\\envs\\myenv\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning and cross validation\n",
    "#I am not going to run this because I already know the results\n",
    "# tune_model = grid_search.fit(X = X_train, y = y_train, **evaluation_parameters)\n",
    "# grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Documents\\GitHub\\Learn-Machine-Learning-From-Scratch\\Additional Applications\\XGBoost\\xgboost.ipynb Cell 27\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#########################################################\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#Setting the cross validation parameters\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m KFold\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tune_control \u001b[39m=\u001b[39m KFold(n_splits \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                      shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                      random_state \u001b[39m=\u001b[39m \u001b[39m1502\u001b[39m)\u001b[39m.\u001b[39msplit(X \u001b[39m=\u001b[39m X_train, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                                 y \u001b[39m=\u001b[39m y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#Parameter tuning part 2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m tune_grid2 \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.05\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m6\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbooster\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39mgbtree\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Documents/GitHub/Learn-Machine-Learning-From-Scratch/Additional%20Applications/XGBoost/xgboost.ipynb#X35sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "\n",
    "#Setting the cross validation parameters\n",
    "from sklearn.model_selection import KFold\n",
    "tune_control = KFold(n_splits = 5, \n",
    "                     shuffle = True, \n",
    "                     random_state = 1502).split(X = X_train, \n",
    "                                                y = y_train)\n",
    "\n",
    "#Parameter tuning part 2\n",
    "\n",
    "tune_grid2 = {\n",
    "    'learning_rate': [0.05],\n",
    "    'max_depth': [6],\n",
    "    'colsample_bytree': [1],\n",
    "    'subsample': [0.9, 1],\n",
    "    'min_child_weight': range(1,5,1),\n",
    "    'gamma': [0, 0.1],\n",
    "    'random_state': [1502],\n",
    "    \"n_estimators\": range(200, 2000, 200),\n",
    "    \"booster\": [\"gbtree\"],\n",
    "}\n",
    "\n",
    "#Cross Validation Assembly\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search2 = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = tune_grid2,\n",
    "                           scoring = \"roc_auc\",\n",
    "                           cv = tune_control,\n",
    "                           n_jobs = 6,\n",
    "                           verbose = 5)\n",
    "\n",
    "#Hyperparameter tuning and cross validation\n",
    "tune_model2 = grid_search2.fit(X = X_train, y = y_train, **evaluation_parameters)\n",
    "grid_search2.best_params_,grid_search2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
